================================================================================
TRANSFORMER INTERNAL STATE ANALYSIS REPORT
================================================================================

üîç ANALYSIS OVERVIEW
----------------------------------------
Number of layers analyzed: 3
Number of sequences: 48
Model dimension: 10

üéØ HIDDEN STATE CLUSTERING ANALYSIS
----------------------------------------
Layer 0:
  ‚Ä¢ Number of clusters identified: 8
  ‚Ä¢ PCA variance explained (first 2 components): 0.281, 0.260
  ‚Ä¢ Total representations: 1584
  ‚Ä¢ Cluster distribution: {np.int32(0): np.int64(239), np.int32(1): np.int64(216), np.int32(2): np.int64(192), np.int32(3): np.int64(137), np.int32(4): np.int64(96), np.int32(5): np.int64(336), np.int32(6): np.int64(240), np.int32(7): np.int64(128)}

Layer 1:
  ‚Ä¢ Number of clusters identified: 8
  ‚Ä¢ PCA variance explained (first 2 components): 0.471, 0.366
  ‚Ä¢ Total representations: 1584
  ‚Ä¢ Cluster distribution: {np.int32(0): np.int64(126), np.int32(1): np.int64(193), np.int32(2): np.int64(192), np.int32(3): np.int64(240), np.int32(4): np.int64(236), np.int32(5): np.int64(176), np.int32(6): np.int64(194), np.int32(7): np.int64(227)}

Layer 2:
  ‚Ä¢ Number of clusters identified: 8
  ‚Ä¢ PCA variance explained (first 2 components): 0.736, 0.120
  ‚Ä¢ Total representations: 1584
  ‚Ä¢ Cluster distribution: {np.int32(0): np.int64(100), np.int32(1): np.int64(160), np.int32(2): np.int64(131), np.int32(3): np.int64(220), np.int32(4): np.int64(154), np.int32(5): np.int64(251), np.int32(6): np.int64(353), np.int32(7): np.int64(215)}

üîÑ STATE TRANSITION ANALYSIS
----------------------------------------
Layer 0:
  ‚Ä¢ State persistence rate: 0.709
  ‚Ä¢ Number of transitions observed: 23
  ‚Ä¢ Diagonal transition strength: 0.685
  ‚Ä¢ Off-diagonal transition strength: 0.045

Layer 1:
  ‚Ä¢ State persistence rate: 0.363
  ‚Ä¢ Number of transitions observed: 18
  ‚Ä¢ Diagonal transition strength: 0.366
  ‚Ä¢ Off-diagonal transition strength: 0.091

Layer 2:
  ‚Ä¢ State persistence rate: 0.561
  ‚Ä¢ Number of transitions observed: 36
  ‚Ä¢ Diagonal transition strength: 0.495
  ‚Ä¢ Off-diagonal transition strength: 0.072

üî¨ PROBING CLASSIFIER RESULTS
----------------------------------------
Layer 0:
  ‚Ä¢ Token prediction accuracy: 0.8013
  ‚Ä¢ Training samples: 1267
  ‚Ä¢ Test samples: 317

Layer 1:
  ‚Ä¢ Token prediction accuracy: 0.9811
  ‚Ä¢ Training samples: 1267
  ‚Ä¢ Test samples: 317

Layer 2:
  ‚Ä¢ Token prediction accuracy: 0.9842
  ‚Ä¢ Training samples: 1267
  ‚Ä¢ Test samples: 317

üí° KEY INSIGHTS
----------------------------------------
‚úÖ PROGRESSIVE REFINEMENT: Token prediction accuracy improves through layers
   Layer 0: 0.8013 ‚Üí Layer 2: 0.9842
‚úÖ CONSISTENT CLUSTERING: All layers identify 8 clusters
‚ö†Ô∏è  Moderate state persistence: 0.544

üèÜ FINAL ASSESSMENT
----------------------------------------
‚úÖ Excellent internal representation quality (high probing accuracy)
‚úÖ Consistent internal clustering across layers
‚úÖ Balanced state persistence (not too rigid, not too chaotic)

üéØ STRONG EVIDENCE: Transformer has learned structured internal FSM representations
   - Clear clustering patterns in hidden states
   - Meaningful state transition dynamics
   - High-quality information encoding

================================================================================