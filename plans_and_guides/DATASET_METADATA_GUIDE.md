# Dataset Metadata Interpretation Guide

This guide explains how to interpret all metadata files generated by the Neural CSSR unified dataset framework.

## Overview

The framework generates rich metadata across multiple categories:
- **Configuration & Generation Info**: What was generated and how
- **Machine Properties**: Ground truth epsilon-machine characteristics  
- **Sequence Statistics**: Raw sequence analysis and information theory
- **Neural Format Metadata**: PyTorch dataset properties
- **Quality Reports**: Coverage validation and quality metrics
- **Statistical Analysis**: Baselines and theoretical limits

---

## 1. Configuration Files

### `experiment_config.yaml`
**Location**: `{output_dir}/experiment_config.yaml`
**Purpose**: Complete configuration used to generate the dataset

```yaml
experiment_name: "small_experiment" 
random_seed: 42
machine_specs:
  - complexity_class: "2-state-binary"     # Machine topology class
    machine_count: 3                       # Number of machines in this class
    samples_per_machine: 500               # Sequences per machine
    weight: 1.0                           # Sampling weight
    topological: true                     # Uniform probabilities
    bias_strength: 0.0                    # Bias strength (0.0=uniform, 1.0=max)
    probability_seed: null                # Seed for random bias generation
    custom_probabilities: null            # Manual transition probabilities
```

**Key Fields**:
- `topological: true` → Uniform transition probabilities (standard epsilon-machines)
- `topological: false` → Non-uniform probabilities (biased machines)
- `bias_strength`: Controls randomization strength for non-topological machines
- `custom_probabilities`: Manual specification of transition probabilities

### `generation_info.yaml`
**Location**: `{output_dir}/generation_info.yaml`
**Purpose**: Generation process metadata and reproducibility info

```yaml
generation_timestamp: "2024-01-15T10:30:45.123456"
framework_version: "1.0.0"
total_generation_time_seconds: 21.34
total_machines_generated: 5
total_sequences_generated: 2500
output_directory: "/path/to/output"
configuration_source: "preset:small"
random_seeds:
  main_seed: 42
  numpy_seed: 42
  torch_seed: 42
validation_passed: true
quality_score: 1.0
```

**Key Metrics**:
- `total_generation_time_seconds`: Performance benchmark
- `quality_score`: Overall dataset quality (0.0-1.0, higher is better)
- `validation_passed`: All quality checks passed
- `random_seeds`: For complete reproducibility

---

## 2. Machine Properties & Ground Truth

### `ground_truth/machine_definitions.json`
**Location**: `{output_dir}/ground_truth/machine_definitions.json`  
**Purpose**: Complete epsilon-machine specifications

```json
{
  "machine_0": {
    "complexity_class": "2-state-binary",
    "states": ["S0", "S1"],
    "alphabet": ["0", "1"],
    "initial_state": "S0",
    "transitions": {
      "(S0, 0)": [["S1", 1.0]],
      "(S0, 1)": [["S0", 1.0]],
      "(S1, 0)": [["S0", 1.0]], 
      "(S1, 1)": [["S1", 1.0]]
    },
    "is_topological": true,
    "statistical_complexity": 1.0,
    "entropy_rate": 1.0,
    "machine_id": "machine_0",
    "generation_config": {
      "topological": true,
      "bias_strength": 0.0,
      "samples_requested": 500
    }
  }
}
```

**Key Fields**:
- `transitions`: Format is `(state, symbol): [[next_state, probability]]`
- `is_topological`: Whether machine has uniform transition probabilities
- `statistical_complexity`: log₂(number of causal states) - measure of memory
- `entropy_rate`: Information generation rate per symbol
- `generation_config`: Configuration used for this specific machine

**Interpreting Transitions**:
- Topological: All probabilities = 1.0 (deterministic given state)
- Non-topological: Probabilities < 1.0, sum to 1.0 per state-symbol pair

### `ground_truth/causal_state_sequences.json` 
**Location**: `{output_dir}/ground_truth/causal_state_sequences.json`
**Purpose**: Ground truth state trajectories for each sequence

```json
{
  "train": [
    {
      "sequence_id": 0,
      "machine_id": "machine_0", 
      "sequence": "01101001",
      "state_trajectory": ["S0", "S1", "S0", "S0", "S1", "S1", "S1", "S0"],
      "length": 8,
      "initial_state": "S0",
      "final_state": "S0"
    }
  ]
}
```

**Usage**: Essential for supervised learning of causal state prediction

---

## 3. Raw Sequence Metadata

### `raw_sequences/sequence_metadata.json`
**Location**: `{output_dir}/raw_sequences/sequence_metadata.json`
**Purpose**: Detailed metadata for each generated sequence

```json
{
  "train_metadata": [
    {
      "sequence_id": 0,
      "machine_id": "machine_0",
      "complexity_class": "2-state-binary", 
      "length": 25,
      "generation_time": 0.001234,
      "machine_properties": {
        "num_states": 2,
        "alphabet_size": 2,
        "is_topological": true,
        "statistical_complexity": 1.0,
        "entropy_rate": 1.0
      },
      "sequence_statistics": {
        "symbol_counts": {"0": 12, "1": 13},
        "symbol_frequencies": {"0": 0.48, "1": 0.52},
        "empirical_entropy": 0.9997
      }
    }
  ],
  "summary": {
    "total_sequences": 2000,
    "total_symbols": 50000,
    "avg_sequence_length": 25.0,
    "unique_machines": 5,
    "complexity_classes": ["2-state-binary", "3-state-binary"]
  }
}
```

**Key Metrics**:
- `symbol_frequencies`: Actual symbol distribution (should reflect bias settings)
- `empirical_entropy`: Measured entropy of this specific sequence
- `generation_time`: Performance tracking per sequence

---

## 4. Neural Format Metadata

### `neural_format/dataset_info.json`
**Location**: `{output_dir}/neural_format/dataset_info.json`
**Purpose**: PyTorch dataset structure and tokenization info

```json
{
  "dataset_structure": {
    "train_size": 1600,
    "val_size": 200, 
    "test_size": 200,
    "total_size": 2000
  },
  "tokenization": {
    "vocab_size": 4,
    "vocabulary": {"0": 0, "1": 1, "<PAD>": 2, "<UNK>": 3},
    "special_tokens": ["<PAD>", "<UNK>"],
    "padding_token_id": 2,
    "unknown_token_id": 3
  },
  "tensor_format": {
    "context_length": 64,
    "sequence_key": "input_ids",
    "attention_mask_key": "attention_mask", 
    "labels_key": "labels",
    "causal_states_key": "causal_states",
    "metadata_keys": ["machine_id", "complexity_class", "sequence_length"]
  },
  "data_statistics": {
    "max_sequence_length": 30,
    "min_sequence_length": 20,
    "avg_sequence_length": 25.0,
    "padding_percentage": 0.15,
    "sequences_requiring_truncation": 0
  }
}
```

**Key Information**:
- `vocab_size`: Total vocabulary including special tokens
- `context_length`: Maximum sequence length (with padding)
- `padding_percentage`: How much of the data is padding tokens
- `sequences_requiring_truncation`: Data loss due to length limits

---

## 5. Statistical Analysis

### `statistical_analysis/information_theory_metrics.json`
**Location**: `{output_dir}/statistical_analysis/information_theory_metrics.json`
**Purpose**: Information-theoretic properties of the dataset

```json
{
  "entropy_analysis": {
    "empirical_entropy_rate": 0.9987,
    "theoretical_entropy_rate": 1.0,
    "entropy_efficiency": 0.9987,
    "conditional_entropies": {
      "H(X|X_1)": 0.9985,
      "H(X|X_2)": 0.9983,
      "H(X|X_3)": 0.9981
    }
  },
  "complexity_analysis": {
    "average_statistical_complexity": 1.2,
    "complexity_distribution": {
      "1.0": 3, 
      "1.585": 2
    },
    "total_causal_states": 6,
    "effective_alphabet_size": 2.0
  },
  "sequence_statistics": {
    "total_symbols": 50000,
    "symbol_distribution": {"0": 0.497, "1": 0.503},
    "n_gram_statistics": {
      "1_grams": {"0": 24850, "1": 25150},
      "2_grams": {"00": 12425, "01": 12425, "10": 12575, "11": 12575},
      "3_grams": {"000": 6212, "001": 6213, "010": 6212, "011": 6213, 
                  "100": 6288, "101": 6287, "110": 6288, "111": 6287}
    }
  }
}
```

**Key Metrics**:
- `entropy_efficiency`: How close to theoretical maximum (1.0 = perfect)
- `conditional_entropies`: Predictability at different context lengths
- `complexity_distribution`: How many machines at each complexity level
- `n_gram_statistics`: Pattern frequencies for classical analysis

### `statistical_analysis/baseline_metrics.json`
**Location**: `{output_dir}/statistical_analysis/baseline_metrics.json`
**Purpose**: Performance baselines for comparison

```json
{
  "random_baselines": {
    "random_cross_entropy": 1.0,
    "random_state_accuracy": 0.5,
    "random_perplexity": 2.0,
    "random_bits_per_symbol": 1.0
  },
  "empirical_baselines": {
    "1_gram_model": {
      "cross_entropy": 0.9987,
      "perplexity": 1.9974,
      "accuracy": 0.5013,
      "coverage": 1.0
    },
    "2_gram_model": {
      "cross_entropy": 0.9985,
      "perplexity": 1.9970,
      "accuracy": 0.5015,
      "coverage": 1.0
    },
    "frequency_baseline": {
      "accuracy": 0.5030,
      "cross_entropy": 0.9993,
      "most_frequent_symbol": "1",
      "most_frequent_probability": 0.503
    }
  },
  "optimal_baselines": {
    "bayes_optimal_accuracy": 0.85,
    "bayes_accuracy_distribution": {
      "mean": 0.85,
      "std": 0.12,
      "min": 0.67,
      "max": 1.0,
      "by_machine": [0.75, 0.85, 1.0, 0.67, 0.91]
    },
    "optimal_cross_entropy": 0.72,
    "optimal_perplexity": 1.65,
    "perfect_state_accuracy": 1.0,
    "mean_statistical_complexity": 1.2
  }
}
```

**Interpretation**:
- **Random baseline**: Performance of random guessing  
- **N-gram models**: Classical statistical models for comparison
- **Frequency baseline**: Always predict most common symbol
- **Optimal baselines**: Theoretical upper bounds with perfect causal state knowledge
- **Coverage**: Fraction of n-grams seen in training that appear in test

**Key Optimal Baselines**:
- **bayes_optimal_accuracy**: Theoretical best next-symbol prediction accuracy
  - Computed as: Σ_s P(s) × max_σ P(σ|s) where s = causal states, σ = symbols
  - Represents upper bound assuming perfect causal state identification
  - Higher values indicate more predictable/biased symbol generation
- **perfect_state_accuracy**: Perfect causal state prediction (always 1.0)
- **optimal_cross_entropy**: Theoretical minimum cross-entropy based on entropy rates

**Performance Expectations**:
- Neural models should beat empirical baselines but may not reach optimal baselines
- Cross-entropy < 1.0 indicates learning
- Accuracy > 0.5 (binary) indicates better than random
- **bayes_optimal_accuracy** provides the theoretical ceiling for next-symbol prediction
- Gap between model accuracy and Bayes optimal shows room for improvement

---

## 6. Quality Reports

### `quality_reports/coverage_analysis.json`
**Location**: `{output_dir}/quality_reports/coverage_analysis.json`
**Purpose**: Validation that dataset covers all intended states/transitions

```json
{
  "state_coverage": {
    "total_states": 6,
    "covered_states": 6,
    "coverage_ratio": 1.0,
    "uncovered_states": [],
    "state_visit_counts": {
      "machine_0_S0": 850,
      "machine_0_S1": 750,
      "machine_1_S0": 650,
      "machine_1_S1": 600,
      "machine_1_S2": 550
    }
  },
  "transition_coverage": {
    "total_transitions": 12,
    "covered_transitions": 12, 
    "coverage_ratio": 1.0,
    "uncovered_transitions": [],
    "transition_counts": {
      "machine_0_(S0,0)->S1": 425,
      "machine_0_(S0,1)->S0": 425,
      "machine_0_(S1,0)->S0": 375,
      "machine_0_(S1,1)->S1": 375
    }
  },
  "coverage_quality_score": 1.0
}
```

**Quality Indicators**:
- `coverage_ratio`: 1.0 = perfect, < 0.9 = concerning
- `uncovered_states/transitions`: Should be empty for good datasets
- Visit counts: Should be roughly balanced (no extremely rare states)

### `quality_reports/distribution_validation.json`
**Location**: `{output_dir}/quality_reports/distribution_validation.json`
**Purpose**: Validate sequence length and symbol distributions

```json
{
  "length_distribution": {
    "target_range": [20, 30],
    "actual_range": [20, 30],
    "mean_length": 25.0,
    "std_length": 2.89,
    "length_diversity_score": 0.95,
    "length_histogram": {
      "20": 95, "21": 105, "22": 110, "25": 120, "30": 85
    }
  },
  "symbol_distribution": {
    "expected_uniform": true,
    "actual_frequencies": {"0": 0.497, "1": 0.503},
    "chi_square_statistic": 0.36,
    "chi_square_p_value": 0.549,
    "distribution_uniformity_score": 0.98
  },
  "split_balance": {
    "train_ratio": 0.80,
    "val_ratio": 0.10, 
    "test_ratio": 0.10,
    "balance_score": 1.0
  },
  "overall_distribution_score": 0.98
}
```

**Quality Thresholds**:
- `length_diversity_score` > 0.8: Good length variety
- `chi_square_p_value` > 0.05: Statistically uniform (for topological machines)
- `distribution_uniformity_score` > 0.9: Good symbol balance
- `balance_score` = 1.0: Perfect train/val/test split

### `quality_reports/quality_summary.json`
**Location**: `{output_dir}/quality_reports/quality_summary.json`
**Purpose**: Overall quality assessment and recommendations

```json
{
  "overall_quality_score": 0.98,
  "component_scores": {
    "coverage_score": 1.0,
    "distribution_score": 0.98,
    "metadata_completeness": 1.0,
    "statistical_consistency": 0.96
  },
  "quality_assessment": "EXCELLENT",
  "recommendations": [],
  "warnings": [],
  "critical_issues": [],
  "dataset_readiness": "READY_FOR_TRAINING"
}
```

**Quality Levels**:
- **EXCELLENT** (≥0.95): Ready for research
- **GOOD** (≥0.85): Usable with minor limitations  
- **ACCEPTABLE** (≥0.70): Usable but check warnings
- **POOR** (<0.70): Investigate critical issues

---

## 7. Interpreting Results for Different Machine Types

### Topological (Uniform) Machines
```json
{
  "is_topological": true,
  "transitions": {
    "(S0, 0)": [["S1", 1.0]],  // Deterministic
    "(S0, 1)": [["S0", 1.0]]   // Deterministic
  },
  "symbol_frequencies": {"0": 0.497, "1": 0.503},  // ~50/50
  "chi_square_p_value": 0.549  // > 0.05 = uniform
}
```

### Non-Topological (Biased) Machines  
```json
{
  "is_topological": false,
  "transitions": {
    "(S0, 0)": [["S1", 0.8]],  // Biased toward S1
    "(S0, 1)": [["S0", 0.2]]   // Biased toward S0
  },
  "symbol_frequencies": {"0": 0.75, "1": 0.25},  // Strong bias
  "chi_square_p_value": 0.001  // < 0.05 = non-uniform
}
```

---

## 8. Common Interpretation Patterns

### Successful Dataset Generation
- `quality_score` ≥ 0.95
- `coverage_ratio` = 1.0 for states and transitions
- `validation_passed` = true
- No items in `critical_issues` or `warnings`
- Symbol frequencies match expectation (uniform vs biased)

### Dataset Issues to Investigate
- `quality_score` < 0.85
- `uncovered_states` or `uncovered_transitions` not empty
- Very uneven `state_visit_counts` 
- `chi_square_p_value` < 0.05 for topological machines
- `sequences_requiring_truncation` > 0

### Performance Baseline Interpretation
- Cross-entropy approaching 1.0 = high randomness/complexity
- Cross-entropy << 1.0 = highly predictable sequences
- N-gram model improvement = presence of learnable patterns
- Frequency baseline >> 0.5 = strong symbol bias present

---

## 9. Using Metadata for Research

### For Neural Network Training
1. Check `neural_format/dataset_info.json` for tensor structure
2. Use `vocabulary` and `special_tokens` for model setup
3. Monitor `padding_percentage` for efficiency
4. Use `baseline_metrics.json` to set performance targets

### For Classical CSSR Comparison
1. Use `raw_sequences/` files as input to classical algorithms
2. Compare results with `ground_truth/machine_definitions.json`
3. Use `information_theory_metrics.json` for theoretical limits
4. Compare against `empirical_baselines` for fair evaluation

### For Transfer Learning Studies
1. Compare `statistical_complexity` distributions across datasets
2. Use `entropy_rate` to measure dataset difficulty
3. Track `quality_score` consistency across scales
4. Use `generation_time` to optimize dataset creation pipeline

This comprehensive metadata enables reproducible research, quality assurance, and deep understanding of dataset properties for Neural CSSR studies.